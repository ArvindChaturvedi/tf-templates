# Senior DevOps Engineer Technical Interview Questions

## AWS & Cloud Engineering Questions

### Question 1: AWS Architecture Design (Advanced)
**Question:** Design a highly available, auto-scaling web application architecture on AWS that serves global traffic. The application has a React frontend, Node.js API backend, and uses PostgreSQL database. Include disaster recovery considerations.

**Expected Answer:**
- **Frontend**: CloudFront CDN with S3 static hosting, multiple edge locations
- **Load Balancing**: Application Load Balancer (ALB) across multiple AZs
- **Compute**: ECS Fargate or EKS for containerized Node.js API with auto-scaling groups
- **Database**: RDS PostgreSQL with Multi-AZ deployment, read replicas in different regions
- **Networking**: VPC with public/private subnets, NAT gateways, security groups
- **Monitoring**: CloudWatch, X-Ray for distributed tracing
- **DR Strategy**: Cross-region backups, RTO/RPO considerations, automated failover
- **Security**: IAM roles, VPC endpoints, encryption at rest/transit

### Question 2: AWS Cost Optimization (Intermediate)
**Question:** Your monthly AWS bill has increased by 40% over the last quarter. Walk me through your systematic approach to identify and reduce costs.

**Expected Answer:**
- **Analysis Tools**: Cost Explorer, AWS Budgets, Trusted Advisor, Cost and Usage Reports
- **Resource Optimization**: Right-sizing EC2 instances, unused EBS volumes, idle load balancers
- **Purchasing Options**: Reserved Instances, Savings Plans, Spot Instances for non-critical workloads
- **Storage Optimization**: S3 lifecycle policies, Intelligent Tiering, EBS volume types
- **Monitoring**: CloudWatch metrics, custom cost alerts, tagging strategy
- **Governance**: Resource tagging, cost allocation, automated cleanup policies

### Question 3: EKS Troubleshooting (Advanced)
**Question:** Pods in your EKS cluster are failing to start with "ImagePullBackOff" errors, but the same images work in other clusters. How do you troubleshoot this?

**Expected Answer:**
- **Initial Investigation**: `kubectl describe pod`, check events and logs
- **Image Registry**: Verify ECR/registry permissions, authentication tokens
- **Network Connectivity**: VPC endpoints, NAT gateway, security groups, NACLs
- **Node Resources**: Check node capacity, disk space, compute resources
- **IAM Permissions**: Service accounts, IRSA (IAM Roles for Service Accounts)
- **DNS Resolution**: CoreDNS configuration, service discovery
- **Tools**: `kubectl logs`, `kubectl get events`, AWS CloudTrail, VPC Flow Logs

## Terraform Questions

### Question 4: Terraform State Management (Advanced)
**Question:** Explain the challenges with Terraform state in a team environment and design a robust state management strategy.

**Expected Answer:**
- **Challenges**: State conflicts, sensitive data, backup/recovery, concurrent access
- **Remote Backend**: S3 backend with DynamoDB for state locking
- **State Structure**: 
  ```hcl
  terraform {
    backend "s3" {
      bucket         = "terraform-state-bucket"
      key            = "env/prod/terraform.tfstate"
      region         = "us-west-2"
      dynamodb_table = "terraform-locks"
      encrypt        = true
    }
  }
  ```
- **Best Practices**: Environment separation, state encryption, versioning, backup strategy
- **Security**: IAM policies, least privilege access, state file encryption
- **Disaster Recovery**: Cross-region replication, automated backups

### Question 5: Terraform Modules (Intermediate)
**Question:** Write a reusable Terraform module for creating a VPC with public and private subnets across multiple AZs.

**Expected Answer:**
```hcl
# modules/vpc/variables.tf
variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
}

variable "environment" {
  description = "Environment name"
  type        = string
}

variable "availability_zones" {
  description = "List of AZs"
  type        = list(string)
}

# modules/vpc/main.tf
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name        = "${var.environment}-vpc"
    Environment = var.environment
  }
}

resource "aws_subnet" "public" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone = var.availability_zones[count.index]
  
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.environment}-public-${count.index + 1}"
    Type = "public"
  }
}

resource "aws_subnet" "private" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + 10)
  availability_zone = var.availability_zones[count.index]
  
  tags = {
    Name = "${var.environment}-private-${count.index + 1}"
    Type = "private"
  }
}
```

## Linux & System Administration

### Question 6: Linux Performance Troubleshooting (Advanced)
**Question:** A production Linux server is experiencing high load averages (>20) but CPU utilization shows only 30%. How do you investigate and resolve this?

**Expected Answer:**
- **Initial Assessment**: Check `uptime`, `top`, `htop` for load average vs CPU usage discrepancy
- **I/O Investigation**: `iostat -x 1`, `iotop` to identify I/O bottlenecks
- **Process Analysis**: `ps aux --sort=-%cpu`, check for processes in D state (uninterruptible sleep)
- **Disk Performance**: `sar -d`, check disk queue lengths, await times
- **Memory Issues**: `free -h`, `vmstat`, check for swapping
- **Network**: `netstat -i`, `ss -tuln` for network I/O issues
- **Solutions**: Optimize disk I/O, add more RAM, tune kernel parameters, identify blocking processes

### Question 7: Linux Security Hardening (Intermediate)
**Question:** List 10 essential security hardening steps for a production Linux server.

**Expected Answer:**
1. **Updates**: Regular security patches, automated updates for critical patches
2. **User Management**: Disable root login, sudo configuration, strong password policies
3. **SSH Security**: Key-based authentication, disable password auth, change default port
4. **Firewall**: iptables/ufw rules, fail2ban for intrusion prevention
5. **File Permissions**: Proper ownership, SUID/SGID review, umask settings
6. **Logging**: centralized logging, log rotation, audit trails
7. **Services**: Disable unnecessary services, regular service audits
8. **Encryption**: Encrypt sensitive data, SSL/TLS certificates
9. **Monitoring**: System monitoring, intrusion detection systems
10. **Backup**: Regular backups, backup verification, disaster recovery testing

## Scripting Questions

### Question 8: Python AWS Automation (Intermediate - 10 mins)
**Question:** Write a Python script that lists all EC2 instances across regions, shows their status, and identifies any instances without proper tags (Name tag missing).

**Expected Answer:**
```python
import boto3
from botocore.exceptions import ClientError

def check_ec2_instances():
    """Check EC2 instances across regions for missing tags"""
    regions = ['us-east-1', 'us-west-2', 'eu-west-1']
    untagged_instances = []
    
    for region in regions:
        try:
            ec2 = boto3.client('ec2', region_name=region)
            response = ec2.describe_instances()
            
            print(f"\n--- Region: {region} ---")
            
            for reservation in response['Reservations']:
                for instance in reservation['Instances']:
                    instance_id = instance['InstanceId']
                    state = instance['State']['Name']
                    instance_type = instance['InstanceType']
                    
                    # Check for Name tag
                    name_tag = None
                    for tag in instance.get('Tags', []):
                        if tag['Key'] == 'Name':
                            name_tag = tag['Value']
                            break
                    
                    if not name_tag:
                        untagged_instances.append({
                            'InstanceId': instance_id,
                            'Region': region,
                            'State': state,
                            'Type': instance_type
                        })
                    
                    print(f"Instance: {instance_id} | State: {state} | Type: {instance_type} | Name: {name_tag or 'MISSING'}")
                    
        except ClientError as e:
            print(f"Error in region {region}: {e}")
    
    # Report untagged instances
    if untagged_instances:
        print(f"\n⚠️  Found {len(untagged_instances)} instances without Name tags:")
        for instance in untagged_instances:
            print(f"  - {instance['InstanceId']} ({instance['Region']}) - {instance['State']}")
    else:
        print("\n✅ All instances have proper Name tags!")

if __name__ == "__main__":
    check_ec2_instances()
```

**Follow-up Questions:**
- How would you handle AWS credentials securely?
- What if you needed to check 20+ regions efficiently?
- How would you modify this to add missing tags automatically?

### Question 9: Shell Script for System Health Check (Intermediate - 8 mins)
**Question:** Write a bash script that performs a quick system health check and alerts if any metrics exceed thresholds (CPU >80%, Memory >85%, Disk >90%).

**Expected Answer:**
```bash
#!/bin/bash

# System Health Check Script
# Thresholds
CPU_THRESHOLD=80
MEM_THRESHOLD=85
DISK_THRESHOLD=90

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "=== System Health Check $(date) ==="

# CPU Check
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
CPU_INT=${CPU_USAGE%.*}  # Convert to integer

if [ "$CPU_INT" -gt "$CPU_THRESHOLD" ]; then
    echo -e "${RED}[CRITICAL] CPU Usage: ${CPU_USAGE}% (>${CPU_THRESHOLD}%)${NC}"
    ALERT=1
else
    echo -e "${GREEN}[OK] CPU Usage: ${CPU_USAGE}%${NC}"
fi

# Memory Check
MEM_USAGE=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100.0}')
if [ "$MEM_USAGE" -gt "$MEM_THRESHOLD" ]; then
    echo -e "${RED}[CRITICAL] Memory Usage: ${MEM_USAGE}% (>${MEM_THRESHOLD}%)${NC}"
    ALERT=1
else
    echo -e "${GREEN}[OK] Memory Usage: ${MEM_USAGE}%${NC}"
fi

# Disk Check
echo "Disk Usage:"
df -h | grep -vE '^Filesystem|tmpfs|cdrom' | awk '{print $5 " " $1}' | while read output;
do
    usage=$(echo $output | awk '{print $1}' | cut -d'%' -f1)
    partition=$(echo $output | awk '{print $2}')
    
    if [ $usage -gt $DISK_THRESHOLD ]; then
        echo -e "${RED}[CRITICAL] Disk ${partition}: ${usage}% (>${DISK_THRESHOLD}%)${NC}"
        export ALERT=1
    else
        echo -e "${GREEN}[OK] Disk ${partition}: ${usage}%${NC}"
    fi
done

# Load Average
LOAD=$(uptime | awk -F'load average:' '{print $2}' | cut -d, -f1 | xargs)
echo -e "${YELLOW}[INFO] Load Average: ${LOAD}${NC}"

# Send alert if any threshold exceeded
if [ "${ALERT}" = "1" ]; then
    echo -e "\n${RED}⚠️  SYSTEM ALERT: One or more thresholds exceeded!${NC}"
    # In production, you'd send email/Slack notification here
    exit 1
else
    echo -e "\n${GREEN}✅ System health is normal${NC}"
    exit 0
fi
```

**Follow-up Questions:**
- How would you schedule this script to run periodically?
- What other metrics would you add for a production server?
- How would you implement alerting (email/Slack)?

## Additional Questions for Deeper Assessment

### Question 10: CI/CD Pipeline Design (Advanced)
**Question:** Design a complete CI/CD pipeline for a microservices application using AWS native services. Include security scanning, testing strategies, and deployment patterns.

**Expected Answer:**
- **Source**: CodeCommit/GitHub with branch protection
- **Build**: CodeBuild with multi-stage builds, dependency caching
- **Testing**: Unit tests, integration tests, security scans (SAST/DAST)
- **Artifacts**: ECR for container images, CodeArtifact for packages
- **Deployment**: CodeDeploy with blue-green deployments
- **Orchestration**: CodePipeline with approval gates
- **Monitoring**: CloudWatch, X-Ray, custom metrics
- **Security**: IAM roles, secrets management, vulnerability scanning
- **Rollback**: Automated rollback triggers, database migration strategies

### Evaluation Criteria:
- **Architecture Thinking**: Can they design scalable, resilient solutions?
- **Problem-Solving**: Systematic approach to troubleshooting
- **Best Practices**: Security, cost optimization, maintainability
- **Practical Experience**: Real-world scenarios and edge cases
- **Communication**: Can they explain complex technical concepts clearly?
- **Scripting Skills**: Clean, maintainable, and efficient code
